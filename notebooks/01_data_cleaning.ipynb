{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6e94fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "094pfx3id6hg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow taxi records: 13,389,587\n",
      "Green taxi records: 221,006\n",
      "HVFHV records: 78,608,184\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "RAW_DIR = Path(\"../input/raw/trip_records\")\n",
    "YELLOW_DIR = RAW_DIR / \"yellow_taxi\"\n",
    "GREEN_DIR = RAW_DIR / \"green_taxi\"\n",
    "HVFHV_DIR = RAW_DIR / \"HVHFV\"\n",
    "\n",
    "# Read all parquet files from each folder and concatenate into single dataframes\n",
    "df_yellow = pd.concat([pd.read_parquet(f) for f in YELLOW_DIR.glob(\"*.parquet\")], ignore_index=True)\n",
    "df_green = pd.concat([pd.read_parquet(f) for f in GREEN_DIR.glob(\"*.parquet\")], ignore_index=True)\n",
    "df_hvfhv = pd.concat([pd.read_parquet(f) for f in HVFHV_DIR.glob(\"*.parquet\")], ignore_index=True)\n",
    "\n",
    "print(f\"Yellow taxi records: {len(df_yellow):,}\")\n",
    "print(f\"Green taxi records: {len(df_green):,}\")\n",
    "print(f\"HVFHV records: {len(df_hvfhv):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "epd1aczzsed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names standardized to lowercase\n",
      "Yellow columns: ['vendorid', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'ratecodeid', 'store_and_fwd_flag', 'pulocationid', 'dolocationid', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
      "Green columns: ['vendorid', 'lpep_pickup_datetime', 'lpep_dropoff_datetime', 'store_and_fwd_flag', 'ratecodeid', 'pulocationid', 'dolocationid', 'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge', 'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge']\n",
      "HVFHV columns: ['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num', 'request_datetime', 'on_scene_datetime', 'pickup_datetime', 'dropoff_datetime', 'pulocationid', 'dolocationid', 'trip_miles', 'trip_time', 'base_passenger_fare', 'tolls', 'bcf', 'sales_tax', 'congestion_surcharge', 'airport_fee', 'tips', 'driver_pay', 'shared_request_flag', 'shared_match_flag', 'access_a_ride_flag', 'wav_request_flag', 'wav_match_flag']\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names to lowercase for all dataframes\n",
    "df_yellow.columns = df_yellow.columns.str.lower()\n",
    "df_green.columns = df_green.columns.str.lower()\n",
    "df_hvfhv.columns = df_hvfhv.columns.str.lower()\n",
    "\n",
    "print(\"Column names standardized to lowercase\")\n",
    "print(f\"Yellow columns: {list(df_yellow.columns)}\")\n",
    "print(f\"Green columns: {list(df_green.columns)}\")\n",
    "print(f\"HVFHV columns: {list(df_hvfhv.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f246bfaf",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5r7iird78q3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Yellow Taxi - Shape: (13389587, 19)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                dtype  null_count  null_pct\n",
      "vendorid                        int32           0      0.00\n",
      "tpep_pickup_datetime   datetime64[us]           0      0.00\n",
      "tpep_dropoff_datetime  datetime64[us]           0      0.00\n",
      "passenger_count               float64     1221622      9.12\n",
      "trip_distance                 float64           0      0.00\n",
      "ratecodeid                    float64     1221622      9.12\n",
      "store_and_fwd_flag             object     1221622      9.12\n",
      "pulocationid                    int32           0      0.00\n",
      "dolocationid                    int32           0      0.00\n",
      "payment_type                    int64           0      0.00\n",
      "fare_amount                   float64           0      0.00\n",
      "extra                         float64           0      0.00\n",
      "mta_tax                       float64           0      0.00\n",
      "tip_amount                    float64           0      0.00\n",
      "tolls_amount                  float64           0      0.00\n",
      "improvement_surcharge         float64           0      0.00\n",
      "total_amount                  float64           0      0.00\n",
      "congestion_surcharge          float64     1221622      9.12\n",
      "airport_fee                   float64     1221622      9.12\n",
      "\n",
      "============================================================\n",
      "Green Taxi - Shape: (221006, 20)\n",
      "============================================================\n",
      "                                dtype  null_count  null_pct\n",
      "vendorid                        int32           0      0.00\n",
      "lpep_pickup_datetime   datetime64[us]           0      0.00\n",
      "lpep_dropoff_datetime  datetime64[us]           0      0.00\n",
      "store_and_fwd_flag             object        8657      3.92\n",
      "ratecodeid                    float64        8657      3.92\n",
      "pulocationid                    int32           0      0.00\n",
      "dolocationid                    int32           0      0.00\n",
      "passenger_count               float64        8657      3.92\n",
      "trip_distance                 float64           0      0.00\n",
      "fare_amount                   float64           0      0.00\n",
      "extra                         float64           0      0.00\n",
      "mta_tax                       float64           0      0.00\n",
      "tip_amount                    float64           0      0.00\n",
      "tolls_amount                  float64           0      0.00\n",
      "ehail_fee                     float64      221006    100.00\n",
      "improvement_surcharge         float64           0      0.00\n",
      "total_amount                  float64           0      0.00\n",
      "payment_type                  float64        8657      3.92\n",
      "trip_type                     float64        8683      3.93\n",
      "congestion_surcharge          float64        8657      3.92\n",
      "\n",
      "============================================================\n",
      "HVFHV - Shape: (78608184, 24)\n",
      "============================================================\n",
      "                               dtype  null_count  null_pct\n",
      "hvfhs_license_num             object           0      0.00\n",
      "dispatching_base_num          object           0      0.00\n",
      "originating_base_num          object    19936866     25.36\n",
      "request_datetime      datetime64[us]           0      0.00\n",
      "on_scene_datetime     datetime64[us]    19936251     25.36\n",
      "pickup_datetime       datetime64[us]           0      0.00\n",
      "dropoff_datetime      datetime64[us]           0      0.00\n",
      "pulocationid                   int32           0      0.00\n",
      "dolocationid                   int32           0      0.00\n",
      "trip_miles                   float64           0      0.00\n",
      "trip_time                      int64           0      0.00\n",
      "base_passenger_fare          float64           0      0.00\n",
      "tolls                        float64           0      0.00\n",
      "bcf                          float64           0      0.00\n",
      "sales_tax                    float64           0      0.00\n",
      "congestion_surcharge         float64           0      0.00\n",
      "airport_fee                  float64           0      0.00\n",
      "tips                         float64           0      0.00\n",
      "driver_pay                   float64           0      0.00\n",
      "shared_request_flag           object           0      0.00\n",
      "shared_match_flag             object           0      0.00\n",
      "access_a_ride_flag            object           0      0.00\n",
      "wav_request_flag              object           0      0.00\n",
      "wav_match_flag                object           0      0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data types and null values for all dataframes\n",
    "def check_data_quality(df, name):\n",
    "    \"\"\"Display data types and null value counts for a dataframe.\"\"\"\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"{name} - Shape: {df.shape}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    info_df = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'null_count': df.isnull().sum(),\n",
    "        'null_pct': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "    })\n",
    "    print(info_df)\n",
    "    print()\n",
    "\n",
    "check_data_quality(df_yellow, \"Yellow Taxi\")\n",
    "check_data_quality(df_green, \"Green Taxi\")\n",
    "check_data_quality(df_hvfhv, \"HVFHV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273be28e",
   "metadata": {},
   "source": [
    "**Finding:** None of the relevant columns for the analysis have null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1l9ymo9lqup",
   "metadata": {},
   "source": [
    "## Yellow Taxi Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6qrj9p9de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi data types after conversion:\n",
      "tpep_pickup_datetime     datetime64[us]\n",
      "tpep_dropoff_datetime    datetime64[us]\n",
      "pulocationid                      Int64\n",
      "dolocationid                      Int64\n",
      "trip_distance                   float64\n",
      "fare_amount                     float64\n",
      "total_amount                    float64\n",
      "wait_time                       Float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Yellow Taxi - Data type conversions based on data dictionary\n",
    "# Kept columns:\n",
    "# - tpep_pickup_datetime, tpep_dropoff_datetime: datetime\n",
    "# - pulocationid, dolocationid, passenger_count: int\n",
    "# - fare_amount, total_amount, trip_distance: float\n",
    "\n",
    "# Keep only relevant columns\n",
    "cols_to_keep = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'pulocationid', 'dolocationid',\n",
    "                'trip_distance', 'fare_amount', 'total_amount']\n",
    "df_yellow = df_yellow[cols_to_keep]\n",
    "\n",
    "# Convert datetime columns\n",
    "datetime_cols = ['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    "for col in datetime_cols:\n",
    "    df_yellow[col] = pd.to_datetime(df_yellow[col])\n",
    "\n",
    "# Convert integer columns (using nullable Int64 for columns that may have nulls)\n",
    "int_cols = ['pulocationid', 'dolocationid']\n",
    "for col in int_cols:\n",
    "    df_yellow[col] = df_yellow[col].astype('Int64')\n",
    "\n",
    "# Wait time is only available for HVFHV; set to null for Yellow Taxi\n",
    "# Use Float64 so aggregates stay numeric\n",
    "if 'wait_time' not in df_yellow.columns:\n",
    "    df_yellow['wait_time'] = pd.Series(pd.NA, index=df_yellow.index, dtype='Float64')\n",
    "\n",
    "print(\"Yellow Taxi data types after conversion:\")\n",
    "print(df_yellow.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "tfpsaew3l7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi - Rows before: 13,389,587\n",
      "Yellow Taxi - Rows after: 13,389,480\n",
      "Yellow Taxi - Rows dropped: 107 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Filter yellow taxi dataframe to keep only January, April, July, October (the sampled months)\n",
    "valid_months = [1, 4, 7, 10]\n",
    "rows_before = len(df_yellow)\n",
    "df_yellow = df_yellow[df_yellow['tpep_pickup_datetime'].dt.month.isin(valid_months)]\n",
    "rows_after = len(df_yellow)\n",
    "rows_dropped = rows_before - rows_after\n",
    "\n",
    "print(f\"Yellow Taxi - Rows before: {rows_before:,}\")\n",
    "print(f\"Yellow Taxi - Rows after: {rows_after:,}\")\n",
    "print(f\"Yellow Taxi - Rows dropped: {rows_dropped:,} ({rows_dropped/rows_before*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a84fbff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Auditing: fare_amount\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    1.338948e+07\n",
      "mean     1.913892e+01\n",
      "std      1.935871e+01\n",
      "min     -2.261200e+03\n",
      "25%      9.300000e+00\n",
      "50%      1.350000e+01\n",
      "75%      2.190000e+01\n",
      "max      5.000000e+03\n",
      "Name: fare_amount, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 4,781 (0.04%)\n",
      "  Negatives: 229,042 (1.71%)\n",
      "\n",
      "  1st percentile: -7.9\n",
      "  99th percentile: 80.0\n",
      "  Below 1st pctl: 131,107\n",
      "  Above 99th pctl: 132,193\n",
      "\n",
      "========================================\n",
      "Auditing: trip_distance\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    1.338948e+07\n",
      "mean     4.837142e+00\n",
      "std      4.096487e+02\n",
      "min      0.000000e+00\n",
      "25%      1.020000e+00\n",
      "50%      1.760000e+00\n",
      "75%      3.360000e+00\n",
      "max      3.663430e+05\n",
      "Name: trip_distance, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 235,868 (1.76%)\n",
      "  Negatives: 0 (0.00%)\n",
      "\n",
      "  1st percentile: 0.0\n",
      "  99th percentile: 20.13\n",
      "  Below 1st pctl: 0\n",
      "  Above 99th pctl: 133,652\n",
      "\n",
      "========================================\n",
      "Auditing: total_amount\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    1.338948e+07\n",
      "mean     2.774446e+01\n",
      "std      2.408909e+01\n",
      "min     -2.265450e+03\n",
      "25%      1.570000e+01\n",
      "50%      2.093000e+01\n",
      "75%      3.024000e+01\n",
      "max      5.000000e+03\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 1,571 (0.01%)\n",
      "  Negatives: 191,057 (1.43%)\n",
      "\n",
      "  1st percentile: -12.6\n",
      "  99th percentile: 104.88\n",
      "  Below 1st pctl: 133,317\n",
      "  Above 99th pctl: 128,100\n"
     ]
    }
   ],
   "source": [
    "def audit_numeric(df, col):\n",
    "    \"\"\"Audit a numeric column for anomalies.\"\"\"\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Auditing: {col}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    series = df[col]\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"\\nBasic Stats:\")\n",
    "    print(series.describe())\n",
    "    \n",
    "    # Check for suspicious values\n",
    "    print(f\"\\nPotential Issues:\")\n",
    "    print(f\"  Nulls: {series.isna().sum():,} ({series.isna().mean()*100:.2f}%)\")\n",
    "    print(f\"  Zeros: {(series == 0).sum():,} ({(series == 0).mean()*100:.2f}%)\")\n",
    "    print(f\"  Negatives: {(series < 0).sum():,} ({(series < 0).mean()*100:.2f}%)\")\n",
    "    \n",
    "    # Outliers (using IQR)\n",
    "    q1, q99 = series.quantile([0.01, 0.99])\n",
    "    print(f\"\\n  1st percentile: {q1}\")\n",
    "    print(f\"  99th percentile: {q99}\")\n",
    "    \n",
    "    extreme_low = (series < q1).sum()\n",
    "    extreme_high = (series > q99).sum()\n",
    "    print(f\"  Below 1st pctl: {extreme_low:,}\")\n",
    "    print(f\"  Above 99th pctl: {extreme_high:,}\")\n",
    "\n",
    "audit_numeric(df_yellow, 'fare_amount')\n",
    "audit_numeric(df_yellow, 'trip_distance')\n",
    "audit_numeric(df_yellow, 'total_amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311a115",
   "metadata": {},
   "source": [
    "**Findings:**\n",
    "* Negative values and zeros in fare_amount and total_amount might be refunds or cancelled trips, having no context I will drop these rows\n",
    "* The max value of trip distance is 366,343 miles which is roughly traveling the circumference of the earth 9 times, New York city spans about 35 miles so I will drop any rows that lie outside the 0.1 to 100 miles range. I will also drop the zeros given it would make no sense to include them in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "063799a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow Taxi - Rows before filtering: 13,389,480\n",
      "Yellow Taxi - Rows after filtering: 12,896,459\n",
      "Yellow Taxi - Rows dropped: 493,021 (3.68%)\n"
     ]
    }
   ],
   "source": [
    "rows_before = len(df_yellow)\n",
    "\n",
    "df_yellow = df_yellow[\n",
    "    (df_yellow['fare_amount'] > 0) &\n",
    "    (df_yellow['total_amount'] > 0) &\n",
    "    (df_yellow['trip_distance'] >= 0.1) &\n",
    "    (df_yellow['trip_distance'] <= 100)\n",
    "]\n",
    "\n",
    "rows_after = len(df_yellow)\n",
    "rows_dropped = rows_before - rows_after\n",
    "\n",
    "print(f\"Yellow Taxi - Rows before filtering: {rows_before:,}\")\n",
    "print(f\"Yellow Taxi - Rows after filtering: {rows_after:,}\")\n",
    "print(f\"Yellow Taxi - Rows dropped: {rows_dropped:,} ({rows_dropped/rows_before*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ictmhdla0ti",
   "metadata": {},
   "source": [
    "## Green Taxi Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "toxj8p7tymf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green Taxi data types after conversion:\n",
      "lpep_pickup_datetime     datetime64[us]\n",
      "lpep_dropoff_datetime    datetime64[us]\n",
      "pulocationid                      Int64\n",
      "dolocationid                      Int64\n",
      "trip_distance                   float64\n",
      "fare_amount                     float64\n",
      "total_amount                    float64\n",
      "wait_time                       Float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Green Taxi - Data type conversions based on data dictionary\n",
    "# Kept columns:\n",
    "# - lpep_pickup_datetime, lpep_dropoff_datetime: datetime\n",
    "# - pulocationid, dolocationid, passenger_count: int\n",
    "# - fare_amount, total_amount, trip_distance: float\n",
    "\n",
    "# Keep only relevant columns\n",
    "cols_to_keep = ['lpep_pickup_datetime', 'lpep_dropoff_datetime', 'pulocationid', 'dolocationid',\n",
    "                'trip_distance', 'fare_amount', 'total_amount']\n",
    "df_green = df_green[cols_to_keep]\n",
    "\n",
    "# Convert datetime columns\n",
    "datetime_cols = ['lpep_pickup_datetime', 'lpep_dropoff_datetime']\n",
    "for col in datetime_cols:\n",
    "    df_green[col] = pd.to_datetime(df_green[col])\n",
    "\n",
    "# Convert integer columns (using nullable Int64 for columns that may have nulls)\n",
    "int_cols = ['pulocationid', 'dolocationid']\n",
    "for col in int_cols:\n",
    "    df_green[col] = df_green[col].astype('Int64')\n",
    "\n",
    "# Wait time is only available for HVFHV; set to null for Green Taxi\n",
    "# Use Float64 so aggregates stay numeric\n",
    "if 'wait_time' not in df_green.columns:\n",
    "    df_green['wait_time'] = pd.Series(pd.NA, index=df_green.index, dtype='Float64')\n",
    "\n",
    "print(\"Green Taxi data types after conversion:\")\n",
    "print(df_green.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b51sqomn2hf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green Taxi - Rows before: 221,006\n",
      "Green Taxi - Rows after: 220,967\n",
      "Green Taxi - Rows dropped: 39 (0.02%)\n"
     ]
    }
   ],
   "source": [
    "# Filter green taxi dataframe to keep only January, April, July, October\n",
    "valid_months = [1, 4, 7, 10]\n",
    "rows_before = len(df_green)\n",
    "df_green = df_green[df_green['lpep_pickup_datetime'].dt.month.isin(valid_months)]\n",
    "rows_after = len(df_green)\n",
    "rows_dropped = rows_before - rows_after\n",
    "\n",
    "print(f\"Green Taxi - Rows before: {rows_before:,}\")\n",
    "print(f\"Green Taxi - Rows after: {rows_after:,}\")\n",
    "print(f\"Green Taxi - Rows dropped: {rows_dropped:,} ({rows_dropped/rows_before*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ec7f4d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Auditing: fare_amount\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    220967.000000\n",
      "mean         18.017807\n",
      "std          16.993607\n",
      "min        -450.000000\n",
      "25%          10.000000\n",
      "50%          13.500000\n",
      "75%          20.500000\n",
      "max        1422.600000\n",
      "Name: fare_amount, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 187 (0.08%)\n",
      "  Negatives: 719 (0.33%)\n",
      "\n",
      "  1st percentile: 3.0\n",
      "  99th percentile: 77.9\n",
      "  Below 1st pctl: 988\n",
      "  Above 99th pctl: 2,203\n",
      "\n",
      "========================================\n",
      "Auditing: trip_distance\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    220967.000000\n",
      "mean         16.692203\n",
      "std         992.180284\n",
      "min           0.000000\n",
      "25%           1.130000\n",
      "50%           1.860000\n",
      "75%           3.230000\n",
      "max      201421.680000\n",
      "Name: trip_distance, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 11,648 (5.27%)\n",
      "  Negatives: 0 (0.00%)\n",
      "\n",
      "  1st percentile: 0.0\n",
      "  99th percentile: 16.0\n",
      "  Below 1st pctl: 0\n",
      "  Above 99th pctl: 2,207\n",
      "\n",
      "========================================\n",
      "Auditing: total_amount\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    220967.000000\n",
      "mean         23.869384\n",
      "std          19.033013\n",
      "min        -451.000000\n",
      "25%          13.800000\n",
      "50%          19.200000\n",
      "75%          27.980000\n",
      "max        1424.100000\n",
      "Name: total_amount, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 144 (0.07%)\n",
      "  Negatives: 734 (0.33%)\n",
      "\n",
      "  1st percentile: 5.2\n",
      "  99th percentile: 93.75\n",
      "  Below 1st pctl: 2,158\n",
      "  Above 99th pctl: 2,200\n"
     ]
    }
   ],
   "source": [
    "audit_numeric(df_green, 'fare_amount')\n",
    "audit_numeric(df_green, 'trip_distance')\n",
    "audit_numeric(df_green, 'total_amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebaec19",
   "metadata": {},
   "source": [
    "**Findings:** Same logic from the yellow taxi dataframe applies to the green taxi dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bae149ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green Taxi - Rows before filtering: 220,967\n",
      "Green Taxi - Rows after filtering: 206,982\n",
      "Green Taxi - Rows dropped: 13,985 (6.33%)\n"
     ]
    }
   ],
   "source": [
    "rows_before = len(df_green)\n",
    "\n",
    "df_green = df_green[\n",
    "    (df_green['fare_amount'] > 0) &\n",
    "    (df_green['total_amount'] > 0) &\n",
    "    (df_green['trip_distance'] >= 0.1) &\n",
    "    (df_green['trip_distance'] <= 100)\n",
    "]\n",
    "\n",
    "rows_after = len(df_green)\n",
    "rows_dropped = rows_before - rows_after\n",
    "\n",
    "print(f\"Green Taxi - Rows before filtering: {rows_before:,}\")\n",
    "print(f\"Green Taxi - Rows after filtering: {rows_after:,}\")\n",
    "print(f\"Green Taxi - Rows dropped: {rows_dropped:,} ({rows_dropped/rows_before*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u6zvjee0i8f",
   "metadata": {},
   "source": [
    "## HVFHV Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "hbz22yp6npd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HVFHV data types after conversion:\n",
      "hvfhs_license_num            category\n",
      "request_datetime       datetime64[us]\n",
      "on_scene_datetime      datetime64[us]\n",
      "pickup_datetime        datetime64[us]\n",
      "dropoff_datetime       datetime64[us]\n",
      "pulocationid                    Int64\n",
      "dolocationid                    Int64\n",
      "trip_miles                    float64\n",
      "trip_time                       Int64\n",
      "base_passenger_fare           float64\n",
      "tips                          float64\n",
      "shared_request_flag          category\n",
      "wav_request_flag             category\n",
      "wav_match_flag               category\n",
      "wait_time                     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# HVFHV - Data type conversions based on data dictionary\n",
    "# Kept columns:\n",
    "# - hvfhs_license_num: category (HV0002=Juno, HV0003=Uber, HV0004=Via, HV0005=Lyft)\n",
    "# - request_datetime, on_scene_datetime, pickup_datetime, dropoff_datetime: datetime\n",
    "# - pulocationid, dolocationid, trip_time: int\n",
    "# - trip_miles, base_passenger_fare, tips: float\n",
    "# - shared_request_flag, wav_request_flag, wav_match_flag: category (Y/N)\n",
    "\n",
    "# Keep only relevant columns\n",
    "cols_to_keep = ['hvfhs_license_num', 'request_datetime', 'on_scene_datetime', 'pickup_datetime',\n",
    "                'dropoff_datetime', 'pulocationid', 'dolocationid', 'trip_miles', 'trip_time',\n",
    "                'base_passenger_fare', 'tips', 'shared_request_flag', 'wav_request_flag',\n",
    "                'wav_match_flag']\n",
    "df_hvfhv = df_hvfhv[cols_to_keep]\n",
    "\n",
    "# Convert datetime columns\n",
    "datetime_cols = ['request_datetime', 'on_scene_datetime', 'pickup_datetime', 'dropoff_datetime']\n",
    "for col in datetime_cols:\n",
    "    df_hvfhv[col] = pd.to_datetime(df_hvfhv[col])\n",
    "\n",
    "# Convert integer columns\n",
    "int_cols = ['pulocationid', 'dolocationid', 'trip_time']\n",
    "for col in int_cols:\n",
    "    df_hvfhv[col] = df_hvfhv[col].astype('Int64')\n",
    "\n",
    "# Convert string/category columns\n",
    "category_cols = ['hvfhs_license_num']\n",
    "for col in category_cols:\n",
    "    df_hvfhv[col] = df_hvfhv[col].astype('category')\n",
    "\n",
    "# Convert Y/N flag columns to category\n",
    "flag_cols = ['shared_request_flag', 'wav_request_flag', 'wav_match_flag']\n",
    "for col in flag_cols:\n",
    "    df_hvfhv[col] = df_hvfhv[col].astype('category')\n",
    "\n",
    "# Wait time in minutes between request and pickup\n",
    "# Will be null when pickup_datetime is missing\n",
    "df_hvfhv['wait_time'] = (\n",
    "    df_hvfhv['pickup_datetime'] - df_hvfhv['request_datetime']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "print(\"HVFHV data types after conversion:\")\n",
    "print(df_hvfhv.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "wsiea1q3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HVFHV - Rows before: 78,608,184\n",
      "HVFHV - Rows after: 78,608,184\n",
      "HVFHV - Rows dropped: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Filter HVFHV dataframe to keep only January, April, July, October\n",
    "valid_months = [1, 4, 7, 10]\n",
    "rows_before = len(df_hvfhv)\n",
    "df_hvfhv = df_hvfhv[df_hvfhv['pickup_datetime'].dt.month.isin(valid_months)]\n",
    "rows_after = len(df_hvfhv)\n",
    "rows_dropped = rows_before - rows_after\n",
    "\n",
    "print(f\"HVFHV - Rows before: {rows_before:,}\")\n",
    "print(f\"HVFHV - Rows after: {rows_after:,}\")\n",
    "print(f\"HVFHV - Rows dropped: {rows_dropped:,} ({rows_dropped/rows_before*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1252b8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Auditing: trip_miles\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    7.860818e+07\n",
      "mean     5.056058e+00\n",
      "std      5.870998e+00\n",
      "min      0.000000e+00\n",
      "25%      1.570000e+00\n",
      "50%      3.000000e+00\n",
      "75%      6.340000e+00\n",
      "max      4.555200e+02\n",
      "Name: trip_miles, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 11,186 (0.01%)\n",
      "  Negatives: 0 (0.00%)\n",
      "\n",
      "  1st percentile: 0.481\n",
      "  99th percentile: 27.14\n",
      "  Below 1st pctl: 785,498\n",
      "  Above 99th pctl: 786,026\n",
      "\n",
      "========================================\n",
      "Auditing: trip_time\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count     78608184.0\n",
      "mean     1183.277328\n",
      "std       835.949352\n",
      "min              0.0\n",
      "25%            599.0\n",
      "50%            966.0\n",
      "75%           1525.0\n",
      "max          52060.0\n",
      "Name: trip_time, dtype: Float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 8 (0.00%)\n",
      "  Negatives: 0 (0.00%)\n",
      "\n",
      "  1st percentile: 196.0\n",
      "  99th percentile: 4115.0\n",
      "  Below 1st pctl: 775,474\n",
      "  Above 99th pctl: 785,470\n",
      "\n",
      "========================================\n",
      "Auditing: base_passenger_fare\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    7.860818e+07\n",
      "mean     2.564873e+01\n",
      "std      2.241229e+01\n",
      "min     -4.309000e+01\n",
      "25%      1.232000e+01\n",
      "50%      1.907000e+01\n",
      "75%      3.067000e+01\n",
      "max      1.911160e+03\n",
      "Name: base_passenger_fare, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 22,859 (0.03%)\n",
      "  Negatives: 3,098 (0.00%)\n",
      "\n",
      "  1st percentile: 6.94\n",
      "  99th percentile: 114.24\n",
      "  Below 1st pctl: 781,532\n",
      "  Above 99th pctl: 785,901\n",
      "\n",
      "========================================\n",
      "Auditing: tips\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    7.860818e+07\n",
      "mean     1.155398e+00\n",
      "std      3.415993e+00\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      2.746400e+02\n",
      "Name: tips, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 63,462,806 (80.73%)\n",
      "  Negatives: 0 (0.00%)\n",
      "\n",
      "  1st percentile: 0.0\n",
      "  99th percentile: 16.19\n",
      "  Below 1st pctl: 0\n",
      "  Above 99th pctl: 784,479\n",
      "\n",
      "========================================\n",
      "Auditing: wait_time\n",
      "========================================\n",
      "\n",
      "Basic Stats:\n",
      "count    7.860818e+07\n",
      "mean     4.379073e+00\n",
      "std      3.186794e+00\n",
      "min     -6.301667e+01\n",
      "25%      2.666667e+00\n",
      "50%      3.833333e+00\n",
      "75%      5.483333e+00\n",
      "max      1.230617e+03\n",
      "Name: wait_time, dtype: float64\n",
      "\n",
      "Potential Issues:\n",
      "  Nulls: 0 (0.00%)\n",
      "  Zeros: 697 (0.00%)\n",
      "  Negatives: 750,982 (0.96%)\n",
      "\n",
      "  1st percentile: 0.38333333333333336\n",
      "  99th percentile: 14.716666666666667\n",
      "  Below 1st pctl: 784,905\n",
      "  Above 99th pctl: 785,577\n"
     ]
    }
   ],
   "source": [
    "audit_numeric(df_hvfhv, 'trip_miles')\n",
    "audit_numeric(df_hvfhv, 'trip_time')\n",
    "audit_numeric(df_hvfhv, 'base_passenger_fare')\n",
    "audit_numeric(df_hvfhv, 'tips')\n",
    "audit_numeric(df_hvfhv, 'wait_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b639ca3b",
   "metadata": {},
   "source": [
    "**Findings:** \n",
    "* Limiting trip distance to 0.1 to 100 miles\n",
    "* Dropping negative and zero values for base_passenger_fare\n",
    "* The tips and trip_time columns look fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "71efd266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HVFHV - Rows before filtering: 78,608,184\n",
      "HVFHV - Rows after filtering: 77,800,930\n",
      "HVFHV - Rows dropped: 807,254 (1.03%)\n"
     ]
    }
   ],
   "source": [
    "rows_before = len(df_hvfhv)\n",
    "\n",
    "df_hvfhv = df_hvfhv[\n",
    "    (df_hvfhv['base_passenger_fare'] > 0) &\n",
    "    (df_hvfhv['trip_miles'] >= 0.1) &\n",
    "    (df_hvfhv['trip_miles'] <= 100) &\n",
    "    (df_hvfhv['wait_time'] > 0)\n",
    "]\n",
    "\n",
    "rows_after = len(df_hvfhv)\n",
    "rows_dropped = rows_before - rows_after\n",
    "\n",
    "print(f\"HVFHV - Rows before filtering: {rows_before:,}\")\n",
    "print(f\"HVFHV - Rows after filtering: {rows_after:,}\")\n",
    "print(f\"HVFHV - Rows dropped: {rows_dropped:,} ({rows_dropped/rows_before*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1d2a0",
   "metadata": {},
   "source": [
    "# Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "95b539a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from df_yellow:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>trip_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_hour  day_of_week  month  is_weekend  trip_minutes\n",
       "0            0            0      1           0     19.800000\n",
       "1            0            0      1           0      6.600000\n",
       "2            0            0      1           0     17.916667\n",
       "3            0            0      1           0      8.300000\n",
       "4            0            0      1           0      6.100000"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_time_features(df, pickup_col, dropoff_col):\n",
    "    \"\"\"Add time-based features for aggregation.\"\"\"\n",
    "    \n",
    "    df['pickup_hour'] = df[pickup_col].dt.hour # Truncating to hour\n",
    "    df['day_of_week'] = df[pickup_col].dt.dayofweek\n",
    "    df['month'] = df[pickup_col].dt.month\n",
    "    df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    df['trip_minutes'] = (df[dropoff_col] - df[pickup_col]).dt.total_seconds() / 60\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply time features to each dataframe\n",
    "df_yellow = add_time_features(df_yellow, 'tpep_pickup_datetime', 'tpep_dropoff_datetime')\n",
    "df_green = add_time_features(df_green, 'lpep_pickup_datetime', 'lpep_dropoff_datetime')\n",
    "df_hvfhv = add_time_features(df_hvfhv, 'pickup_datetime', 'dropoff_datetime')\n",
    "\n",
    "print(f\"Sample from df_yellow:\")\n",
    "df_yellow[['pickup_hour', 'day_of_week', 'month', 'is_weekend', 'trip_minutes']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "rmtf3ij5zx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yellow aggregated: (11278, 14)\n",
      "Green aggregated: (5017, 14)\n",
      "HVFHV aggregated: (12444, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>avg_fare</th>\n",
       "      <th>median_fare</th>\n",
       "      <th>avg_trip_distance</th>\n",
       "      <th>avg_trip_minutes</th>\n",
       "      <th>total_fare</th>\n",
       "      <th>total_miles</th>\n",
       "      <th>avg_wait_time</th>\n",
       "      <th>std_wait_time</th>\n",
       "      <th>fare_per_mile</th>\n",
       "      <th>vehicle_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>46.60</td>\n",
       "      <td>9.40000</td>\n",
       "      <td>23.816667</td>\n",
       "      <td>93.2</td>\n",
       "      <td>18.80</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.957447</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.06000</td>\n",
       "      <td>4.983333</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>94.339623</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>73.812500</td>\n",
       "      <td>57.95</td>\n",
       "      <td>14.02625</td>\n",
       "      <td>15.702083</td>\n",
       "      <td>590.5</td>\n",
       "      <td>112.21</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.262454</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>11.40</td>\n",
       "      <td>7.36000</td>\n",
       "      <td>14.088889</td>\n",
       "      <td>92.1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.171196</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>132.166667</td>\n",
       "      <td>119.00</td>\n",
       "      <td>8.53000</td>\n",
       "      <td>10.077778</td>\n",
       "      <td>396.5</td>\n",
       "      <td>25.59</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>15.494334</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pulocationid  pickup_hour  is_weekend  trip_count    avg_fare  median_fare  \\\n",
       "0             1            0           0           2   46.600000        46.60   \n",
       "1             1            2           0           1  100.000000       100.00   \n",
       "2             1            5           0           8   73.812500        57.95   \n",
       "3             1            6           0           3   30.700000        11.40   \n",
       "4             1            6           1           3  132.166667       119.00   \n",
       "\n",
       "   avg_trip_distance  avg_trip_minutes  total_fare  total_miles  \\\n",
       "0            9.40000         23.816667        93.2        18.80   \n",
       "1            1.06000          4.983333       100.0         1.06   \n",
       "2           14.02625         15.702083       590.5       112.21   \n",
       "3            7.36000         14.088889        92.1        22.08   \n",
       "4            8.53000         10.077778       396.5        25.59   \n",
       "\n",
       "   avg_wait_time  std_wait_time  fare_per_mile vehicle_type  \n",
       "0           <NA>           <NA>       4.957447       yellow  \n",
       "1           <NA>           <NA>      94.339623       yellow  \n",
       "2           <NA>           <NA>       5.262454       yellow  \n",
       "3           <NA>           <NA>       4.171196       yellow  \n",
       "4           <NA>           <NA>      15.494334       yellow  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aggregate_to_zone_time(df, vehicle_type, fare_col='fare_amount', distance_col='trip_distance'):\n",
    "    \"\"\"Aggregate trip data to zone x hour x is_weekend level.\"\"\"\n",
    "    \n",
    "    agg = df.groupby(['pulocationid', 'pickup_hour', 'is_weekend']).agg(\n",
    "        trip_count=('pickup_hour', 'count'),\n",
    "        avg_fare=(fare_col, 'mean'),\n",
    "        median_fare=(fare_col, 'median'),\n",
    "        avg_trip_distance=(distance_col, 'mean'),\n",
    "        avg_trip_minutes=('trip_minutes', 'mean'),\n",
    "        total_fare=(fare_col, 'sum'),\n",
    "        total_miles=(distance_col, 'sum'),\n",
    "        avg_wait_time=('wait_time', 'mean'),\n",
    "        std_wait_time=('wait_time', 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    agg['fare_per_mile'] = agg['total_fare'] / agg['total_miles']\n",
    "    agg['vehicle_type'] = vehicle_type\n",
    "    \n",
    "    return agg\n",
    "\n",
    "# Aggregate each dataframe\n",
    "agg_yellow = aggregate_to_zone_time(df_yellow, 'yellow', fare_col='fare_amount', distance_col='trip_distance')\n",
    "agg_green = aggregate_to_zone_time(df_green, 'green', fare_col='fare_amount', distance_col='trip_distance')\n",
    "agg_hvfhv = aggregate_to_zone_time(df_hvfhv, 'hvfhv', fare_col='base_passenger_fare', distance_col='trip_miles')\n",
    "\n",
    "print(f\"Yellow aggregated: {agg_yellow.shape}\")\n",
    "print(f\"Green aggregated: {agg_green.shape}\")\n",
    "print(f\"HVFHV aggregated: {agg_hvfhv.shape}\")\n",
    "\n",
    "agg_yellow.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6ocsmvz65eg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined aggregated dataframe shape: (28739, 14)\n",
      "\n",
      "Vehicle type distribution:\n",
      "vehicle_type\n",
      "hvfhv     12444\n",
      "yellow    11278\n",
      "green      5017\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_17276\\1607680300.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_aggregated = pd.concat([agg_yellow, agg_green, agg_hvfhv], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Combine all aggregated dataframes into a single one\n",
    "df_aggregated = pd.concat([agg_yellow, agg_green, agg_hvfhv], ignore_index=True)\n",
    "\n",
    "print(f\"Combined aggregated dataframe shape: {df_aggregated.shape}\")\n",
    "print(f\"\\nVehicle type distribution:\")\n",
    "print(df_aggregated['vehicle_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "766a31fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zone-level aggregated dataframe shape: (767, 12)\n",
      "\n",
      "Vehicle type distribution:\n",
      "vehicle_type\n",
      "hvfhv     262\n",
      "yellow    261\n",
      "green     244\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_17276\\937381944.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_aggregated_zone = pd.concat([agg_zone_yellow, agg_zone_green, agg_zone_hvfhv], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Create zone-level aggregation (group by pulocationid only)\n",
    "def aggregate_to_zone(df, vehicle_type, fare_col='fare_amount', distance_col='trip_distance'):\n",
    "    \"\"\"Aggregate trip data to zone level only.\"\"\"\n",
    "    \n",
    "    agg = df.groupby(['pulocationid']).agg(\n",
    "        trip_count=('pickup_hour', 'count'),\n",
    "        avg_fare=(fare_col, 'mean'),\n",
    "        median_fare=(fare_col, 'median'),\n",
    "        avg_trip_distance=(distance_col, 'mean'),\n",
    "        avg_trip_minutes=('trip_minutes', 'mean'),\n",
    "        total_fare=(fare_col, 'sum'),\n",
    "        total_miles=(distance_col, 'sum'),\n",
    "        avg_wait_time=('wait_time', 'mean'),\n",
    "        std_wait_time=('wait_time', 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    agg['fare_per_mile'] = agg['total_fare'] / agg['total_miles']\n",
    "    agg['vehicle_type'] = vehicle_type\n",
    "    \n",
    "    return agg\n",
    "\n",
    "# Aggregate each dataframe at zone level\n",
    "agg_zone_yellow = aggregate_to_zone(df_yellow, 'yellow', fare_col='fare_amount', distance_col='trip_distance')\n",
    "agg_zone_green = aggregate_to_zone(df_green, 'green', fare_col='fare_amount', distance_col='trip_distance')\n",
    "agg_zone_hvfhv = aggregate_to_zone(df_hvfhv, 'hvfhv', fare_col='base_passenger_fare', distance_col='trip_miles')\n",
    "\n",
    "# Combine into df_aggregated_zone\n",
    "df_aggregated_zone = pd.concat([agg_zone_yellow, agg_zone_green, agg_zone_hvfhv], ignore_index=True)\n",
    "\n",
    "print(f\"Zone-level aggregated dataframe shape: {df_aggregated_zone.shape}\")\n",
    "print(f\"\\nVehicle type distribution:\")\n",
    "print(df_aggregated_zone['vehicle_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f44845",
   "metadata": {},
   "source": [
    "## Joining taxi zone information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4sg1h28k7ur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zone lookup shape: (265, 4)\n",
      "Columns: ['locationid', 'borough', 'zone', 'service_zone']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationid</th>\n",
       "      <th>borough</th>\n",
       "      <th>zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationid        borough                     zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load taxi zone lookup and standardize column names to lowercase\n",
    "ZONE_LOOKUP_PATH = Path(\"../input/raw/other/taxi_zone_lookup.csv\")\n",
    "df_zones = pd.read_csv(ZONE_LOOKUP_PATH)\n",
    "df_zones.columns = df_zones.columns.str.lower()\n",
    "\n",
    "print(f\"Zone lookup shape: {df_zones.shape}\")\n",
    "print(f\"Columns: {list(df_zones.columns)}\")\n",
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f0qghbr45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_aggregated shape after join: (28739, 17)\n",
      "Columns: ['pulocationid', 'pickup_hour', 'is_weekend', 'trip_count', 'avg_fare', 'median_fare', 'avg_trip_distance', 'avg_trip_minutes', 'total_fare', 'total_miles', 'avg_wait_time', 'std_wait_time', 'fare_per_mile', 'vehicle_type', 'borough', 'zone', 'service_zone']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>avg_fare</th>\n",
       "      <th>median_fare</th>\n",
       "      <th>avg_trip_distance</th>\n",
       "      <th>avg_trip_minutes</th>\n",
       "      <th>total_fare</th>\n",
       "      <th>total_miles</th>\n",
       "      <th>avg_wait_time</th>\n",
       "      <th>std_wait_time</th>\n",
       "      <th>fare_per_mile</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>borough</th>\n",
       "      <th>zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>46.60</td>\n",
       "      <td>9.40000</td>\n",
       "      <td>23.816667</td>\n",
       "      <td>93.2</td>\n",
       "      <td>18.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.957447</td>\n",
       "      <td>yellow</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.06000</td>\n",
       "      <td>4.983333</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.339623</td>\n",
       "      <td>yellow</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>73.812500</td>\n",
       "      <td>57.95</td>\n",
       "      <td>14.02625</td>\n",
       "      <td>15.702083</td>\n",
       "      <td>590.5</td>\n",
       "      <td>112.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.262454</td>\n",
       "      <td>yellow</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>11.40</td>\n",
       "      <td>7.36000</td>\n",
       "      <td>14.088889</td>\n",
       "      <td>92.1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.171196</td>\n",
       "      <td>yellow</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>132.166667</td>\n",
       "      <td>119.00</td>\n",
       "      <td>8.53000</td>\n",
       "      <td>10.077778</td>\n",
       "      <td>396.5</td>\n",
       "      <td>25.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.494334</td>\n",
       "      <td>yellow</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pulocationid  pickup_hour  is_weekend  trip_count    avg_fare  median_fare  \\\n",
       "0             1            0           0           2   46.600000        46.60   \n",
       "1             1            2           0           1  100.000000       100.00   \n",
       "2             1            5           0           8   73.812500        57.95   \n",
       "3             1            6           0           3   30.700000        11.40   \n",
       "4             1            6           1           3  132.166667       119.00   \n",
       "\n",
       "   avg_trip_distance  avg_trip_minutes  total_fare  total_miles  \\\n",
       "0            9.40000         23.816667        93.2        18.80   \n",
       "1            1.06000          4.983333       100.0         1.06   \n",
       "2           14.02625         15.702083       590.5       112.21   \n",
       "3            7.36000         14.088889        92.1        22.08   \n",
       "4            8.53000         10.077778       396.5        25.59   \n",
       "\n",
       "   avg_wait_time  std_wait_time  fare_per_mile vehicle_type borough  \\\n",
       "0            NaN            NaN       4.957447       yellow     EWR   \n",
       "1            NaN            NaN      94.339623       yellow     EWR   \n",
       "2            NaN            NaN       5.262454       yellow     EWR   \n",
       "3            NaN            NaN       4.171196       yellow     EWR   \n",
       "4            NaN            NaN      15.494334       yellow     EWR   \n",
       "\n",
       "             zone service_zone  \n",
       "0  Newark Airport          EWR  \n",
       "1  Newark Airport          EWR  \n",
       "2  Newark Airport          EWR  \n",
       "3  Newark Airport          EWR  \n",
       "4  Newark Airport          EWR  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join zone information to df_aggregated (zone x hour x is_weekend level)\n",
    "df_aggregated = df_aggregated.merge(\n",
    "    df_zones[['locationid', 'borough', 'zone', 'service_zone']],\n",
    "    left_on='pulocationid',\n",
    "    right_on='locationid',\n",
    "    how='left'\n",
    ").drop(columns=['locationid'])\n",
    "\n",
    "print(f\"df_aggregated shape after join: {df_aggregated.shape}\")\n",
    "print(f\"Columns: {list(df_aggregated.columns)}\")\n",
    "df_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ppgc163ddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_aggregated_zone shape after join: (767, 15)\n",
      "Columns: ['pulocationid', 'trip_count', 'avg_fare', 'median_fare', 'avg_trip_distance', 'avg_trip_minutes', 'total_fare', 'total_miles', 'avg_wait_time', 'std_wait_time', 'fare_per_mile', 'vehicle_type', 'borough', 'zone', 'service_zone']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>avg_fare</th>\n",
       "      <th>median_fare</th>\n",
       "      <th>avg_trip_distance</th>\n",
       "      <th>avg_trip_minutes</th>\n",
       "      <th>total_fare</th>\n",
       "      <th>total_miles</th>\n",
       "      <th>avg_wait_time</th>\n",
       "      <th>std_wait_time</th>\n",
       "      <th>fare_per_mile</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>borough</th>\n",
       "      <th>zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>83.239804</td>\n",
       "      <td>90.00</td>\n",
       "      <td>9.177516</td>\n",
       "      <td>15.027560</td>\n",
       "      <td>12735.69</td>\n",
       "      <td>1404.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.069971</td>\n",
       "      <td>yellow</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>51.946429</td>\n",
       "      <td>53.75</td>\n",
       "      <td>14.197143</td>\n",
       "      <td>30.564286</td>\n",
       "      <td>727.25</td>\n",
       "      <td>198.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.658935</td>\n",
       "      <td>yellow</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>35.980780</td>\n",
       "      <td>36.50</td>\n",
       "      <td>9.242260</td>\n",
       "      <td>43.164167</td>\n",
       "      <td>17990.39</td>\n",
       "      <td>4621.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.893072</td>\n",
       "      <td>yellow</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20292</td>\n",
       "      <td>17.499698</td>\n",
       "      <td>15.60</td>\n",
       "      <td>2.928168</td>\n",
       "      <td>16.181122</td>\n",
       "      <td>355103.87</td>\n",
       "      <td>59418.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.976329</td>\n",
       "      <td>yellow</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>165</td>\n",
       "      <td>11.293273</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.442242</td>\n",
       "      <td>27.574747</td>\n",
       "      <td>1863.39</td>\n",
       "      <td>1227.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.517456</td>\n",
       "      <td>yellow</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arrochar/Fort Wadsworth</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pulocationid  trip_count   avg_fare  median_fare  avg_trip_distance  \\\n",
       "0             1         153  83.239804        90.00           9.177516   \n",
       "1             2          14  51.946429        53.75          14.197143   \n",
       "2             3         500  35.980780        36.50           9.242260   \n",
       "3             4       20292  17.499698        15.60           2.928168   \n",
       "4             6         165  11.293273         0.01           7.442242   \n",
       "\n",
       "   avg_trip_minutes  total_fare  total_miles  avg_wait_time  std_wait_time  \\\n",
       "0         15.027560    12735.69      1404.16            NaN            NaN   \n",
       "1         30.564286      727.25       198.76            NaN            NaN   \n",
       "2         43.164167    17990.39      4621.13            NaN            NaN   \n",
       "3         16.181122   355103.87     59418.39            NaN            NaN   \n",
       "4         27.574747     1863.39      1227.97            NaN            NaN   \n",
       "\n",
       "   fare_per_mile vehicle_type        borough                     zone  \\\n",
       "0       9.069971       yellow            EWR           Newark Airport   \n",
       "1       3.658935       yellow         Queens              Jamaica Bay   \n",
       "2       3.893072       yellow          Bronx  Allerton/Pelham Gardens   \n",
       "3       5.976329       yellow      Manhattan            Alphabet City   \n",
       "4       1.517456       yellow  Staten Island  Arrochar/Fort Wadsworth   \n",
       "\n",
       "  service_zone  \n",
       "0          EWR  \n",
       "1    Boro Zone  \n",
       "2    Boro Zone  \n",
       "3  Yellow Zone  \n",
       "4    Boro Zone  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join zone information to df_aggregated_zone (zone level only)\n",
    "df_aggregated_zone = df_aggregated_zone.merge(\n",
    "    df_zones[['locationid', 'borough', 'zone', 'service_zone']],\n",
    "    left_on='pulocationid',\n",
    "    right_on='locationid',\n",
    "    how='left'\n",
    ").drop(columns=['locationid'])\n",
    "\n",
    "print(f\"df_aggregated_zone shape after join: {df_aggregated_zone.shape}\")\n",
    "print(f\"Columns: {list(df_aggregated_zone.columns)}\")\n",
    "df_aggregated_zone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f56a81",
   "metadata": {},
   "source": [
    "## Joining U.S Census Bureau Information Via Area-Weighted Spatial Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9cfc0320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census data shape: (2327, 67)\n",
      "Columns: ['total_population', 'population_below_poverty', 'hh_income_under_10k', 'hh_income_10k_to_15k', 'hh_income_15k_to_20k', 'hh_income_20k_to_25k', 'hh_income_25k_to_30k', 'hh_income_30k_to_35k', 'hh_income_35k_to_40k', 'hh_income_40k_to_45k', 'hh_income_45k_to_50k', 'hh_income_50k_to_60k', 'hh_income_60k_to_75k', 'hh_income_75k_to_100k', 'hh_income_100k_to_125k', 'hh_income_125k_to_150k', 'hh_income_150k_to_200k', 'hh_income_200k_plus', 'total_households', 'households_no_vehicle', 'commuters_total', 'commute_car_truck_van', 'commute_drove_alone', 'commute_carpooled', 'commute_public_transit', 'commute_taxi', 'commute_motorcycle', 'commute_bicycle', 'commute_walked', 'commute_other', 'commute_work_from_home', 'travel_time_total', 'travel_time_under_5min', 'travel_time_5_to_9min', 'travel_time_10_to_14min', 'travel_time_15_to_19min', 'travel_time_20_to_24min', 'travel_time_25_to_29min', 'travel_time_30_to_34min', 'travel_time_35_to_39min', 'travel_time_40_to_44min', 'travel_time_45_to_59min', 'travel_time_60_to_89min', 'travel_time_90min_plus', 'pop_16_plus', 'in_labor_force', 'civilian_labor_force', 'employed', 'unemployed', 'GEO_ID', 'state', 'county', 'tract', 'armed_forces', 'not_in_labor_force', 'race_total', 'race_white_alone', 'race_black_alone', 'race_american_indian_alone', 'race_asian_alone', 'race_pacific_islander_alone', 'race_other_alone', 'race_two_or_more', 'ethnicity_hispanic_latino', 'population_with_disability', 'geoid', 'borough']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_population</th>\n",
       "      <th>population_below_poverty</th>\n",
       "      <th>hh_income_under_10k</th>\n",
       "      <th>hh_income_10k_to_15k</th>\n",
       "      <th>hh_income_15k_to_20k</th>\n",
       "      <th>hh_income_20k_to_25k</th>\n",
       "      <th>hh_income_25k_to_30k</th>\n",
       "      <th>hh_income_30k_to_35k</th>\n",
       "      <th>hh_income_35k_to_40k</th>\n",
       "      <th>hh_income_40k_to_45k</th>\n",
       "      <th>...</th>\n",
       "      <th>race_black_alone</th>\n",
       "      <th>race_american_indian_alone</th>\n",
       "      <th>race_asian_alone</th>\n",
       "      <th>race_pacific_islander_alone</th>\n",
       "      <th>race_other_alone</th>\n",
       "      <th>race_two_or_more</th>\n",
       "      <th>ethnicity_hispanic_latino</th>\n",
       "      <th>population_with_disability</th>\n",
       "      <th>geoid</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36061000100</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2568.0</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>36061000201</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6934.0</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>6922.0</td>\n",
       "      <td>36061000202</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36061000500</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10179.0</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>...</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2978.0</td>\n",
       "      <td>9982.0</td>\n",
       "      <td>36061000600</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_population  population_below_poverty  hh_income_under_10k  \\\n",
       "0               0.0                       0.0                  0.0   \n",
       "1            2568.0                    1337.0                128.0   \n",
       "2            6934.0                    1724.0                294.0   \n",
       "3               0.0                       0.0                  0.0   \n",
       "4           10179.0                    3660.0                653.0   \n",
       "\n",
       "   hh_income_10k_to_15k  hh_income_15k_to_20k  hh_income_20k_to_25k  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                 126.0                  43.0                  49.0   \n",
       "2                 590.0                 159.0                  59.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                 902.0                 418.0                 309.0   \n",
       "\n",
       "   hh_income_25k_to_30k  hh_income_30k_to_35k  hh_income_35k_to_40k  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                  19.0                  20.0                  41.0   \n",
       "2                 106.0                 157.0                 227.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                 208.0                 149.0                 390.0   \n",
       "\n",
       "   hh_income_40k_to_45k  ...  race_black_alone  race_american_indian_alone  \\\n",
       "0                   0.0  ...               0.0                         0.0   \n",
       "1                  58.0  ...             359.0                         0.0   \n",
       "2                 111.0  ...            1012.0                        15.0   \n",
       "3                   0.0  ...               0.0                         0.0   \n",
       "4                 483.0  ...             681.0                         0.0   \n",
       "\n",
       "   race_asian_alone  race_pacific_islander_alone  race_other_alone  \\\n",
       "0               0.0                          0.0               0.0   \n",
       "1             486.0                          0.0               0.0   \n",
       "2            1566.0                          0.0               0.0   \n",
       "3               0.0                          0.0               0.0   \n",
       "4            5023.0                          0.0             233.0   \n",
       "\n",
       "   race_two_or_more  ethnicity_hispanic_latino  population_with_disability  \\\n",
       "0               0.0                        0.0                         0.0   \n",
       "1              65.0                     1487.0                      2521.0   \n",
       "2              87.0                     2506.0                      6922.0   \n",
       "3               0.0                        0.0                         0.0   \n",
       "4             129.0                     2978.0                      9982.0   \n",
       "\n",
       "         geoid    borough  \n",
       "0  36061000100  Manhattan  \n",
       "1  36061000201  Manhattan  \n",
       "2  36061000202  Manhattan  \n",
       "3  36061000500  Manhattan  \n",
       "4  36061000600  Manhattan  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load census data fetched from src/fetch_census_data.py script\n",
    "CENSUS_PATH = Path(\"../input/raw/census/nyc_census_tracts.parquet\")\n",
    "df_census = pd.read_parquet(CENSUS_PATH, engine='pyarrow')\n",
    "\n",
    "print(f\"Census data shape: {df_census.shape}\")\n",
    "print(f\"Columns: {list(df_census.columns)}\")\n",
    "df_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc18ac",
   "metadata": {},
   "source": [
    "### Why Area-Weighted Spatial Join?\n",
    "\n",
    "Census data is collected at the **census tract level** (~2,300 tracts in NYC), while taxi trip data is aggregated at the **taxi zone level** (265 zones defined by the TLC). These geographic boundaries do not align, a single taxi zone may contain multiple census tracts, and a census tract may span multiple taxi zones.\n",
    "\n",
    "To properly join census demographics to taxi zones, we will use an **area-weighted spatial join**:\n",
    "\n",
    "1. **Load shapefiles** for both geographies (census tracts and taxi zones)\n",
    "2. **Compute polygon intersections** using `geopandas.overlay()` to find where tracts and zones overlap\n",
    "3. **Calculate area weights** for each intersection: `weight = intersection_area / tract_area`\n",
    "4. **Distribute census counts proportionally** by multiplying each tract's counts by the overlap weight\n",
    "5. **Aggregate to taxi zone level** by summing all weighted values per zone\n",
    "\n",
    "**Why this works for count data:**\n",
    "If a census tract with 1,000 people is 60% within Zone A and 40% within Zone B, we allocate ~600 people to Zone A and ~400 to Zone B. This assumes uniform population distribution within tracts - not perfect, but a reasonable approximation given the granularity of census tracts.\n",
    "\n",
    "**Important:** This method only works for **count-based variables** (population, households, etc.) that can be summed. Median or average values (like median income) cannot be properly aggregated this way, which is why we use income bracket counts instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "vqzmw5cur4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxi zones shape: (263, 7)\n",
      "Taxi zones CRS: EPSG:2263\n",
      "Taxi zones columns: ['OBJECTID', 'Shape_Leng', 'Shape_Area', 'zone', 'LocationID', 'borough', 'geometry']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.918 192536.086, 933091.011 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((1033269.244 172126.008, 103343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.77 256767.698, 1026495.593 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.467 203714.076, 992068.667 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.31 144283.336, 936046.565 144...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0         1    0.116357    0.000782           Newark Airport           1   \n",
       "1         2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2         3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3         4    0.043567    0.000112            Alphabet City           4   \n",
       "4         5    0.092146    0.000498            Arden Heights           5   \n",
       "\n",
       "         borough                                           geometry  \n",
       "0            EWR  POLYGON ((933100.918 192536.086, 933091.011 19...  \n",
       "1         Queens  MULTIPOLYGON (((1033269.244 172126.008, 103343...  \n",
       "2          Bronx  POLYGON ((1026308.77 256767.698, 1026495.593 2...  \n",
       "3      Manhattan  POLYGON ((992073.467 203714.076, 992068.667 20...  \n",
       "4  Staten Island  POLYGON ((935843.31 144283.336, 936046.565 144...  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define paths to shapefiles\n",
    "SHAPEFILE_DIR = Path(\"../input/raw/shapefiles\")\n",
    "TAXI_ZONES_SHP = SHAPEFILE_DIR / \"taxi_zones\" / \"taxi_zones.shp\"\n",
    "CENSUS_TRACTS_SHP = SHAPEFILE_DIR / \"tiger_census_tracts\" / \"tl_2025_36_tract.shp\"\n",
    "\n",
    "# Load taxi zones shapefile\n",
    "gdf_taxi_zones = gpd.read_file(TAXI_ZONES_SHP)\n",
    "print(f\"Taxi zones shape: {gdf_taxi_zones.shape}\")\n",
    "print(f\"Taxi zones CRS: {gdf_taxi_zones.crs}\")\n",
    "print(f\"Taxi zones columns: {list(gdf_taxi_zones.columns)}\")\n",
    "gdf_taxi_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "qfspbpxchf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census tracts shape: (5411, 14)\n",
      "Census tracts CRS: EPSG:4269\n",
      "Census tracts columns: ['STATEFP', 'COUNTYFP', 'TRACTCE', 'GEOID', 'GEOIDFQ', 'NAME', 'NAMELSAD', 'MTFCC', 'FUNCSTAT', 'ALAND', 'AWATER', 'INTPTLAT', 'INTPTLON', 'geometry']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEFP</th>\n",
       "      <th>COUNTYFP</th>\n",
       "      <th>TRACTCE</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>GEOIDFQ</th>\n",
       "      <th>NAME</th>\n",
       "      <th>NAMELSAD</th>\n",
       "      <th>MTFCC</th>\n",
       "      <th>FUNCSTAT</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLON</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>029</td>\n",
       "      <td>008400</td>\n",
       "      <td>36029008400</td>\n",
       "      <td>1400000US36029008400</td>\n",
       "      <td>84</td>\n",
       "      <td>Census Tract 84</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>10966624</td>\n",
       "      <td>3505091</td>\n",
       "      <td>+42.9713848</td>\n",
       "      <td>-078.9194986</td>\n",
       "      <td>POLYGON ((-78.94456 42.98506, -78.94216 42.992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>103</td>\n",
       "      <td>123600</td>\n",
       "      <td>36103123600</td>\n",
       "      <td>1400000US36103123600</td>\n",
       "      <td>1236</td>\n",
       "      <td>Census Tract 1236</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>2302367</td>\n",
       "      <td>1082191</td>\n",
       "      <td>+40.6608399</td>\n",
       "      <td>-073.4145754</td>\n",
       "      <td>POLYGON ((-73.42559 40.65629, -73.42529 40.656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>103</td>\n",
       "      <td>146001</td>\n",
       "      <td>36103146001</td>\n",
       "      <td>1400000US36103146001</td>\n",
       "      <td>1460.01</td>\n",
       "      <td>Census Tract 1460.01</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>2225464</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.7703277</td>\n",
       "      <td>-073.2532537</td>\n",
       "      <td>POLYGON ((-73.26159 40.76307, -73.2615 40.7636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>103</td>\n",
       "      <td>190402</td>\n",
       "      <td>36103190402</td>\n",
       "      <td>1400000US36103190402</td>\n",
       "      <td>1904.02</td>\n",
       "      <td>Census Tract 1904.02</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>44073411</td>\n",
       "      <td>23956</td>\n",
       "      <td>+40.8468673</td>\n",
       "      <td>-072.6336641</td>\n",
       "      <td>POLYGON ((-72.72668 40.8339, -72.72515 40.8387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>103</td>\n",
       "      <td>158709</td>\n",
       "      <td>36103158709</td>\n",
       "      <td>1400000US36103158709</td>\n",
       "      <td>1587.09</td>\n",
       "      <td>Census Tract 1587.09</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>13099359</td>\n",
       "      <td>110761</td>\n",
       "      <td>+40.8517499</td>\n",
       "      <td>-072.9216255</td>\n",
       "      <td>POLYGON ((-72.94716 40.8556, -72.94649 40.8576...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATEFP COUNTYFP TRACTCE        GEOID               GEOIDFQ     NAME  \\\n",
       "0      36      029  008400  36029008400  1400000US36029008400       84   \n",
       "1      36      103  123600  36103123600  1400000US36103123600     1236   \n",
       "2      36      103  146001  36103146001  1400000US36103146001  1460.01   \n",
       "3      36      103  190402  36103190402  1400000US36103190402  1904.02   \n",
       "4      36      103  158709  36103158709  1400000US36103158709  1587.09   \n",
       "\n",
       "               NAMELSAD  MTFCC FUNCSTAT     ALAND   AWATER     INTPTLAT  \\\n",
       "0       Census Tract 84  G5020        S  10966624  3505091  +42.9713848   \n",
       "1     Census Tract 1236  G5020        S   2302367  1082191  +40.6608399   \n",
       "2  Census Tract 1460.01  G5020        S   2225464        0  +40.7703277   \n",
       "3  Census Tract 1904.02  G5020        S  44073411    23956  +40.8468673   \n",
       "4  Census Tract 1587.09  G5020        S  13099359   110761  +40.8517499   \n",
       "\n",
       "       INTPTLON                                           geometry  \n",
       "0  -078.9194986  POLYGON ((-78.94456 42.98506, -78.94216 42.992...  \n",
       "1  -073.4145754  POLYGON ((-73.42559 40.65629, -73.42529 40.656...  \n",
       "2  -073.2532537  POLYGON ((-73.26159 40.76307, -73.2615 40.7636...  \n",
       "3  -072.6336641  POLYGON ((-72.72668 40.8339, -72.72515 40.8387...  \n",
       "4  -072.9216255  POLYGON ((-72.94716 40.8556, -72.94649 40.8576...  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load census tracts shapefile\n",
    "gdf_census_tracts = gpd.read_file(CENSUS_TRACTS_SHP)\n",
    "print(f\"Census tracts shape: {gdf_census_tracts.shape}\")\n",
    "print(f\"Census tracts CRS: {gdf_census_tracts.crs}\")\n",
    "print(f\"Census tracts columns: {list(gdf_census_tracts.columns)}\")\n",
    "gdf_census_tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6nawc7ho9xh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC census tracts shape after filtering: (2327, 14)\n",
      "Tracts per county:\n",
      "COUNTYFP\n",
      "047    805\n",
      "081    725\n",
      "005    361\n",
      "061    310\n",
      "085    126\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter census tracts to only NYC counties (5 boroughs)\n",
    "# NYC county FIPS codes: 061 (Manhattan), 047 (Brooklyn), 081 (Queens), 005 (Bronx), 085 (Staten Island)\n",
    "nyc_county_fips = ['061', '047', '081', '005', '085']\n",
    "gdf_census_tracts = gdf_census_tracts[gdf_census_tracts['COUNTYFP'].isin(nyc_county_fips)]\n",
    "\n",
    "print(f\"NYC census tracts shape after filtering: {gdf_census_tracts.shape}\")\n",
    "print(f\"Tracts per county:\")\n",
    "print(gdf_census_tracts['COUNTYFP'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "rhlj1ssrxhc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxi zones CRS after reprojection: EPSG:2263\n",
      "Census tracts CRS after reprojection: EPSG:2263\n"
     ]
    }
   ],
   "source": [
    "# Ensure both GeoDataFrames use the same CRS (coordinate reference system)\n",
    "# Reproject to a projected CRS suitable for area calculations (NAD83 / New York Long Island - EPSG:2263)\n",
    "target_crs = \"EPSG:2263\"\n",
    "\n",
    "gdf_taxi_zones = gdf_taxi_zones.to_crs(target_crs)\n",
    "gdf_census_tracts = gdf_census_tracts.to_crs(target_crs)\n",
    "\n",
    "print(f\"Taxi zones CRS after reprojection: {gdf_taxi_zones.crs}\")\n",
    "print(f\"Census tracts CRS after reprojection: {gdf_census_tracts.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6zhwtevvzsn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample GEOIDs from shapefile: ['36085024402', '36085027705', '36085012806', '36047024400', '36047023000']\n",
      "Sample GEOIDs from census data: ['36061000100', '36061000201', '36061000202', '36061000500', '36061000600']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the area of each census tract (before intersection)\n",
    "gdf_census_tracts['tract_area'] = gdf_census_tracts.geometry.area\n",
    "\n",
    "# Create GEOID to match census data format (state + county + tract)\n",
    "gdf_census_tracts['geoid'] = '36' + gdf_census_tracts['COUNTYFP'] + gdf_census_tracts['TRACTCE']\n",
    "\n",
    "print(f\"Sample GEOIDs from shapefile: {gdf_census_tracts['geoid'].head().tolist()}\")\n",
    "print(f\"Sample GEOIDs from census data: {df_census['geoid'].head().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2lyn3o7uv94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census tracts with data shape: (2327, 82)\n",
      "Tracts in shapefile: 2327\n",
      "Tracts in census data: 2327\n",
      "Matched tracts: 2327\n"
     ]
    }
   ],
   "source": [
    "# Merge census demographic data with census tract geometries\n",
    "gdf_census_with_data = gdf_census_tracts.merge(\n",
    "    df_census,\n",
    "    on='geoid',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Census tracts with data shape: {gdf_census_with_data.shape}\")\n",
    "print(f\"Tracts in shapefile: {len(gdf_census_tracts)}\")\n",
    "print(f\"Tracts in census data: {len(df_census)}\")\n",
    "print(f\"Matched tracts: {len(gdf_census_with_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f6ntth1wc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxi zones prepared for overlay: (263, 2)\n"
     ]
    }
   ],
   "source": [
    "# Prepare taxi zones for overlay - keep only necessary columns\n",
    "gdf_taxi_zones_simple = gdf_taxi_zones[['LocationID', 'geometry']].copy()\n",
    "gdf_taxi_zones_simple = gdf_taxi_zones_simple.rename(columns={'LocationID': 'locationid'})\n",
    "\n",
    "# Ensure locationid is integer type\n",
    "gdf_taxi_zones_simple['locationid'] = gdf_taxi_zones_simple['locationid'].astype(int)\n",
    "\n",
    "print(f\"Taxi zones prepared for overlay: {gdf_taxi_zones_simple.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "61mu5bjnztl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection result shape: (5219, 83)\n",
      "Sample of intersection:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>locationid</th>\n",
       "      <th>total_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36085024402</td>\n",
       "      <td>44</td>\n",
       "      <td>4909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36085024402</td>\n",
       "      <td>84</td>\n",
       "      <td>4909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36085027705</td>\n",
       "      <td>23</td>\n",
       "      <td>6094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36085027705</td>\n",
       "      <td>118</td>\n",
       "      <td>6094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36085012806</td>\n",
       "      <td>172</td>\n",
       "      <td>5308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36085012806</td>\n",
       "      <td>176</td>\n",
       "      <td>5308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36047024400</td>\n",
       "      <td>22</td>\n",
       "      <td>3697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36047024400</td>\n",
       "      <td>26</td>\n",
       "      <td>3697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36047023000</td>\n",
       "      <td>26</td>\n",
       "      <td>4887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36047023100</td>\n",
       "      <td>17</td>\n",
       "      <td>3546.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         geoid  locationid  total_population\n",
       "0  36085024402          44            4909.0\n",
       "1  36085024402          84            4909.0\n",
       "2  36085027705          23            6094.0\n",
       "3  36085027705         118            6094.0\n",
       "4  36085012806         172            5308.0\n",
       "5  36085012806         176            5308.0\n",
       "6  36047024400          22            3697.0\n",
       "7  36047024400          26            3697.0\n",
       "8  36047023000          26            4887.0\n",
       "9  36047023100          17            3546.0"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform spatial overlay (intersection) between census tracts and taxi zones\n",
    "# This creates polygons representing the intersection of each tract with each zone\n",
    "gdf_intersection = gpd.overlay(gdf_census_with_data, gdf_taxi_zones_simple, how='intersection')\n",
    "\n",
    "print(f\"Intersection result shape: {gdf_intersection.shape}\")\n",
    "print(f\"Sample of intersection:\")\n",
    "gdf_intersection[['geoid', 'locationid', 'total_population']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ou1oq98hrdk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area weight statistics:\n",
      "count    5.219000e+03\n",
      "mean     4.237352e-01\n",
      "std      4.821187e-01\n",
      "min      3.115767e-12\n",
      "25%      4.165894e-05\n",
      "50%      3.456858e-03\n",
      "75%      9.998805e-01\n",
      "max      1.000000e+00\n",
      "Name: area_weight, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the area of each intersection polygon\n",
    "gdf_intersection['intersection_area'] = gdf_intersection.geometry.area\n",
    "\n",
    "# Calculate the weight: proportion of tract area in this intersection\n",
    "gdf_intersection['area_weight'] = gdf_intersection['intersection_area'] / gdf_intersection['tract_area']\n",
    "\n",
    "# Sanity check: weights should be between 0 and 1\n",
    "print(f\"Area weight statistics:\")\n",
    "print(gdf_intersection['area_weight'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "nrsqdt92aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of census columns to aggregate: 61\n"
     ]
    }
   ],
   "source": [
    "# Define the census columns to aggregate (all count-based columns)\n",
    "census_count_columns = [\n",
    "    # Population\n",
    "    'total_population', 'population_below_poverty',\n",
    "    \n",
    "    # Income brackets\n",
    "    'hh_income_under_10k', 'hh_income_10k_to_15k', 'hh_income_15k_to_20k',\n",
    "    'hh_income_20k_to_25k', 'hh_income_25k_to_30k', 'hh_income_30k_to_35k',\n",
    "    'hh_income_35k_to_40k', 'hh_income_40k_to_45k', 'hh_income_45k_to_50k',\n",
    "    'hh_income_50k_to_60k', 'hh_income_60k_to_75k', 'hh_income_75k_to_100k',\n",
    "    'hh_income_100k_to_125k', 'hh_income_125k_to_150k', 'hh_income_150k_to_200k',\n",
    "    'hh_income_200k_plus',\n",
    "    \n",
    "    # Households & vehicles\n",
    "    'total_households', 'households_no_vehicle',\n",
    "    \n",
    "    # Commute mode\n",
    "    'commuters_total', 'commute_car_truck_van', 'commute_drove_alone',\n",
    "    'commute_carpooled', 'commute_public_transit', 'commute_taxi',\n",
    "    'commute_motorcycle', 'commute_bicycle', 'commute_walked',\n",
    "    'commute_other', 'commute_work_from_home',\n",
    "    \n",
    "    # Travel time\n",
    "    'travel_time_total', 'travel_time_under_5min', 'travel_time_5_to_9min',\n",
    "    'travel_time_10_to_14min', 'travel_time_15_to_19min', 'travel_time_20_to_24min',\n",
    "    'travel_time_25_to_29min', 'travel_time_30_to_34min', 'travel_time_35_to_39min',\n",
    "    'travel_time_40_to_44min', 'travel_time_45_to_59min', 'travel_time_60_to_89min',\n",
    "    'travel_time_90min_plus',\n",
    "    \n",
    "    # Employment\n",
    "    'pop_16_plus', 'in_labor_force', 'civilian_labor_force',\n",
    "    'employed', 'unemployed', 'armed_forces', 'not_in_labor_force',\n",
    "    \n",
    "    # Race/Ethnicity\n",
    "    'race_total', 'race_white_alone', 'race_black_alone',\n",
    "    'race_american_indian_alone', 'race_asian_alone', 'race_pacific_islander_alone',\n",
    "    'race_other_alone', 'race_two_or_more', 'ethnicity_hispanic_latino',\n",
    "    \n",
    "    # Disability\n",
    "    'population_with_disability'\n",
    "]\n",
    "\n",
    "print(f\"Number of census columns to aggregate: {len(census_count_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2noqcbhg4pt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied area weights to all census columns\n",
      "Sample weighted values for total_population:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>locationid</th>\n",
       "      <th>total_population</th>\n",
       "      <th>area_weight</th>\n",
       "      <th>total_population_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36085024402</td>\n",
       "      <td>44</td>\n",
       "      <td>4909.0</td>\n",
       "      <td>0.457237</td>\n",
       "      <td>2244.575493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36085024402</td>\n",
       "      <td>84</td>\n",
       "      <td>4909.0</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.843885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36085027705</td>\n",
       "      <td>23</td>\n",
       "      <td>6094.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.026072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36085027705</td>\n",
       "      <td>118</td>\n",
       "      <td>6094.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>6093.973901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36085012806</td>\n",
       "      <td>172</td>\n",
       "      <td>5308.0</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>4.438543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36085012806</td>\n",
       "      <td>176</td>\n",
       "      <td>5308.0</td>\n",
       "      <td>0.676991</td>\n",
       "      <td>3593.470378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36047024400</td>\n",
       "      <td>22</td>\n",
       "      <td>3697.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.123575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36047024400</td>\n",
       "      <td>26</td>\n",
       "      <td>3697.0</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>3696.876425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36047023000</td>\n",
       "      <td>26</td>\n",
       "      <td>4887.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4887.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36047023100</td>\n",
       "      <td>17</td>\n",
       "      <td>3546.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.043248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         geoid  locationid  total_population  area_weight  \\\n",
       "0  36085024402          44            4909.0     0.457237   \n",
       "1  36085024402          84            4909.0     0.000172   \n",
       "2  36085027705          23            6094.0     0.000004   \n",
       "3  36085027705         118            6094.0     0.999996   \n",
       "4  36085012806         172            5308.0     0.000836   \n",
       "5  36085012806         176            5308.0     0.676991   \n",
       "6  36047024400          22            3697.0     0.000033   \n",
       "7  36047024400          26            3697.0     0.999967   \n",
       "8  36047023000          26            4887.0     1.000000   \n",
       "9  36047023100          17            3546.0     0.000012   \n",
       "\n",
       "   total_population_weighted  \n",
       "0                2244.575493  \n",
       "1                   0.843885  \n",
       "2                   0.026072  \n",
       "3                6093.973901  \n",
       "4                   4.438543  \n",
       "5                3593.470378  \n",
       "6                   0.123575  \n",
       "7                3696.876425  \n",
       "8                4887.000000  \n",
       "9                   0.043248  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply area weights to all census count columns\n",
    "# This distributes counts proportionally based on geographic overlap\n",
    "for col in census_count_columns:\n",
    "    gdf_intersection[f'{col}_weighted'] = gdf_intersection[col] * gdf_intersection['area_weight']\n",
    "\n",
    "print(\"Applied area weights to all census columns\")\n",
    "print(f\"Sample weighted values for total_population:\")\n",
    "gdf_intersection[['geoid', 'locationid', 'total_population', 'area_weight', 'total_population_weighted']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "g0biejdx6lo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census data aggregated to taxi zone level: (259, 62)\n",
      "Number of taxi zones with census data: 259\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationid</th>\n",
       "      <th>total_population</th>\n",
       "      <th>population_below_poverty</th>\n",
       "      <th>hh_income_under_10k</th>\n",
       "      <th>hh_income_10k_to_15k</th>\n",
       "      <th>hh_income_15k_to_20k</th>\n",
       "      <th>hh_income_20k_to_25k</th>\n",
       "      <th>hh_income_25k_to_30k</th>\n",
       "      <th>hh_income_30k_to_35k</th>\n",
       "      <th>hh_income_35k_to_40k</th>\n",
       "      <th>...</th>\n",
       "      <th>race_total</th>\n",
       "      <th>race_white_alone</th>\n",
       "      <th>race_black_alone</th>\n",
       "      <th>race_american_indian_alone</th>\n",
       "      <th>race_asian_alone</th>\n",
       "      <th>race_pacific_islander_alone</th>\n",
       "      <th>race_other_alone</th>\n",
       "      <th>race_two_or_more</th>\n",
       "      <th>ethnicity_hispanic_latino</th>\n",
       "      <th>population_with_disability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>30030</td>\n",
       "      <td>3539</td>\n",
       "      <td>687</td>\n",
       "      <td>412</td>\n",
       "      <td>234</td>\n",
       "      <td>177</td>\n",
       "      <td>373</td>\n",
       "      <td>255</td>\n",
       "      <td>194</td>\n",
       "      <td>...</td>\n",
       "      <td>30030</td>\n",
       "      <td>4987</td>\n",
       "      <td>10104</td>\n",
       "      <td>55</td>\n",
       "      <td>3315</td>\n",
       "      <td>31</td>\n",
       "      <td>230</td>\n",
       "      <td>518</td>\n",
       "      <td>10790</td>\n",
       "      <td>28445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>19705</td>\n",
       "      <td>4814</td>\n",
       "      <td>1070</td>\n",
       "      <td>944</td>\n",
       "      <td>516</td>\n",
       "      <td>567</td>\n",
       "      <td>345</td>\n",
       "      <td>207</td>\n",
       "      <td>274</td>\n",
       "      <td>...</td>\n",
       "      <td>19705</td>\n",
       "      <td>6385</td>\n",
       "      <td>2320</td>\n",
       "      <td>94</td>\n",
       "      <td>2958</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>833</td>\n",
       "      <td>7036</td>\n",
       "      <td>19687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>26418</td>\n",
       "      <td>1254</td>\n",
       "      <td>199</td>\n",
       "      <td>110</td>\n",
       "      <td>165</td>\n",
       "      <td>100</td>\n",
       "      <td>129</td>\n",
       "      <td>272</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>26418</td>\n",
       "      <td>18430</td>\n",
       "      <td>302</td>\n",
       "      <td>7</td>\n",
       "      <td>3281</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>359</td>\n",
       "      <td>3898</td>\n",
       "      <td>26402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>14356</td>\n",
       "      <td>1475</td>\n",
       "      <td>340</td>\n",
       "      <td>141</td>\n",
       "      <td>182</td>\n",
       "      <td>155</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>14356</td>\n",
       "      <td>7980</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>3211</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>169</td>\n",
       "      <td>2265</td>\n",
       "      <td>14278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationid  total_population  population_below_poverty  \\\n",
       "0           2                45                         4   \n",
       "1           3             30030                      3539   \n",
       "2           4             19705                      4814   \n",
       "3           5             26418                      1254   \n",
       "4           6             14356                      1475   \n",
       "\n",
       "   hh_income_under_10k  hh_income_10k_to_15k  hh_income_15k_to_20k  \\\n",
       "0                    0                     1                     0   \n",
       "1                  687                   412                   234   \n",
       "2                 1070                   944                   516   \n",
       "3                  199                   110                   165   \n",
       "4                  340                   141                   182   \n",
       "\n",
       "   hh_income_20k_to_25k  hh_income_25k_to_30k  hh_income_30k_to_35k  \\\n",
       "0                     0                     0                     1   \n",
       "1                   177                   373                   255   \n",
       "2                   567                   345                   207   \n",
       "3                   100                   129                   272   \n",
       "4                   155                    85                   144   \n",
       "\n",
       "   hh_income_35k_to_40k  ...  race_total  race_white_alone  race_black_alone  \\\n",
       "0                     0  ...          45                36                 1   \n",
       "1                   194  ...       30030              4987             10104   \n",
       "2                   274  ...       19705              6385              2320   \n",
       "3                   182  ...       26418             18430               302   \n",
       "4                   202  ...       14356              7980               706   \n",
       "\n",
       "   race_american_indian_alone  race_asian_alone  race_pacific_islander_alone  \\\n",
       "0                           0                 4                            0   \n",
       "1                          55              3315                           31   \n",
       "2                          94              2958                            5   \n",
       "3                           7              3281                            0   \n",
       "4                           0              3211                            0   \n",
       "\n",
       "   race_other_alone  race_two_or_more  ethnicity_hispanic_latino  \\\n",
       "0                 0                 1                          4   \n",
       "1               230               518                      10790   \n",
       "2                75               833                       7036   \n",
       "3               141               359                       3898   \n",
       "4                25               169                       2265   \n",
       "\n",
       "   population_with_disability  \n",
       "0                          45  \n",
       "1                       28445  \n",
       "2                       19687  \n",
       "3                       26402  \n",
       "4                       14278  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate weighted census data to taxi zone level\n",
    "# Sum all weighted values for each taxi zone\n",
    "weighted_columns = [f'{col}_weighted' for col in census_count_columns]\n",
    "\n",
    "df_census_by_zone = gdf_intersection.groupby('locationid')[weighted_columns].sum().reset_index()\n",
    "\n",
    "# Rename columns back to original names (remove '_weighted' suffix)\n",
    "df_census_by_zone.columns = ['locationid'] + census_count_columns\n",
    "\n",
    "# Round to integers since these are count data\n",
    "for col in census_count_columns:\n",
    "    df_census_by_zone[col] = df_census_by_zone[col].round(0).astype(int)\n",
    "\n",
    "print(f\"Census data aggregated to taxi zone level: {df_census_by_zone.shape}\")\n",
    "print(f\"Number of taxi zones with census data: {len(df_census_by_zone)}\")\n",
    "df_census_by_zone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ufxkzufc589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original total population (census data): 8,516,202\n",
      "Aggregated total population (by zone): 8,080,887\n",
      "Difference: 435,315 (5.11%)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Compare total population before and after spatial join\n",
    "original_population = df_census['total_population'].sum()\n",
    "aggregated_population = df_census_by_zone['total_population'].sum()\n",
    "\n",
    "print(f\"Original total population (census data): {original_population:,.0f}\")\n",
    "print(f\"Aggregated total population (by zone): {aggregated_population:,.0f}\")\n",
    "print(f\"Difference: {abs(original_population - aggregated_population):,.0f} ({abs(original_population - aggregated_population) / original_population * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe058aa",
   "metadata": {},
   "source": [
    "**Note:** Small differences are expected due to:\n",
    "  - Census tracts that don't overlap with any taxi zone (e.g., water areas)\n",
    "  - Floating point precision in area calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "soyz20vjw3h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_aggregated shape after census join: (28739, 78)\n",
      "Columns: ['pulocationid', 'pickup_hour', 'is_weekend', 'trip_count', 'avg_fare', 'median_fare', 'avg_trip_distance', 'avg_trip_minutes', 'total_fare', 'total_miles', 'avg_wait_time', 'std_wait_time', 'fare_per_mile', 'vehicle_type', 'borough', 'zone', 'service_zone', 'total_population', 'population_below_poverty', 'hh_income_under_10k', 'hh_income_10k_to_15k', 'hh_income_15k_to_20k', 'hh_income_20k_to_25k', 'hh_income_25k_to_30k', 'hh_income_30k_to_35k', 'hh_income_35k_to_40k', 'hh_income_40k_to_45k', 'hh_income_45k_to_50k', 'hh_income_50k_to_60k', 'hh_income_60k_to_75k', 'hh_income_75k_to_100k', 'hh_income_100k_to_125k', 'hh_income_125k_to_150k', 'hh_income_150k_to_200k', 'hh_income_200k_plus', 'total_households', 'households_no_vehicle', 'commuters_total', 'commute_car_truck_van', 'commute_drove_alone', 'commute_carpooled', 'commute_public_transit', 'commute_taxi', 'commute_motorcycle', 'commute_bicycle', 'commute_walked', 'commute_other', 'commute_work_from_home', 'travel_time_total', 'travel_time_under_5min', 'travel_time_5_to_9min', 'travel_time_10_to_14min', 'travel_time_15_to_19min', 'travel_time_20_to_24min', 'travel_time_25_to_29min', 'travel_time_30_to_34min', 'travel_time_35_to_39min', 'travel_time_40_to_44min', 'travel_time_45_to_59min', 'travel_time_60_to_89min', 'travel_time_90min_plus', 'pop_16_plus', 'in_labor_force', 'civilian_labor_force', 'employed', 'unemployed', 'armed_forces', 'not_in_labor_force', 'race_total', 'race_white_alone', 'race_black_alone', 'race_american_indian_alone', 'race_asian_alone', 'race_pacific_islander_alone', 'race_other_alone', 'race_two_or_more', 'ethnicity_hispanic_latino', 'population_with_disability']\n",
      "\n",
      "Null values in census columns (zones without census data):\n",
      "21594\n"
     ]
    }
   ],
   "source": [
    "# Join census data to df_aggregated (zone x hour x is_weekend level)\n",
    "df_aggregated = df_aggregated.merge(\n",
    "    df_census_by_zone,\n",
    "    left_on='pulocationid',\n",
    "    right_on='locationid',\n",
    "    how='left'\n",
    ").drop(columns=['locationid'])\n",
    "\n",
    "print(f\"df_aggregated shape after census join: {df_aggregated.shape}\")\n",
    "print(f\"Columns: {list(df_aggregated.columns)}\")\n",
    "print(f\"\\nNull values in census columns (zones without census data):\")\n",
    "print(df_aggregated[census_count_columns].isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "73a143d9muh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_aggregated_zone shape after census join: (767, 76)\n",
      "Columns: ['pulocationid', 'trip_count', 'avg_fare', 'median_fare', 'avg_trip_distance', 'avg_trip_minutes', 'total_fare', 'total_miles', 'avg_wait_time', 'std_wait_time', 'fare_per_mile', 'vehicle_type', 'borough', 'zone', 'service_zone', 'total_population', 'population_below_poverty', 'hh_income_under_10k', 'hh_income_10k_to_15k', 'hh_income_15k_to_20k', 'hh_income_20k_to_25k', 'hh_income_25k_to_30k', 'hh_income_30k_to_35k', 'hh_income_35k_to_40k', 'hh_income_40k_to_45k', 'hh_income_45k_to_50k', 'hh_income_50k_to_60k', 'hh_income_60k_to_75k', 'hh_income_75k_to_100k', 'hh_income_100k_to_125k', 'hh_income_125k_to_150k', 'hh_income_150k_to_200k', 'hh_income_200k_plus', 'total_households', 'households_no_vehicle', 'commuters_total', 'commute_car_truck_van', 'commute_drove_alone', 'commute_carpooled', 'commute_public_transit', 'commute_taxi', 'commute_motorcycle', 'commute_bicycle', 'commute_walked', 'commute_other', 'commute_work_from_home', 'travel_time_total', 'travel_time_under_5min', 'travel_time_5_to_9min', 'travel_time_10_to_14min', 'travel_time_15_to_19min', 'travel_time_20_to_24min', 'travel_time_25_to_29min', 'travel_time_30_to_34min', 'travel_time_35_to_39min', 'travel_time_40_to_44min', 'travel_time_45_to_59min', 'travel_time_60_to_89min', 'travel_time_90min_plus', 'pop_16_plus', 'in_labor_force', 'civilian_labor_force', 'employed', 'unemployed', 'armed_forces', 'not_in_labor_force', 'race_total', 'race_white_alone', 'race_black_alone', 'race_american_indian_alone', 'race_asian_alone', 'race_pacific_islander_alone', 'race_other_alone', 'race_two_or_more', 'ethnicity_hispanic_latino', 'population_with_disability']\n",
      "\n",
      "Null values in census columns (zones without census data):\n",
      "793\n"
     ]
    }
   ],
   "source": [
    "# Join census data to df_aggregated_zone (zone level only)\n",
    "df_aggregated_zone = df_aggregated_zone.merge(\n",
    "    df_census_by_zone,\n",
    "    left_on='pulocationid',\n",
    "    right_on='locationid',\n",
    "    how='left'\n",
    ").drop(columns=['locationid'])\n",
    "\n",
    "print(f\"df_aggregated_zone shape after census join: {df_aggregated_zone.shape}\")\n",
    "print(f\"Columns: {list(df_aggregated_zone.columns)}\")\n",
    "print(f\"\\nNull values in census columns (zones without census data):\")\n",
    "print(df_aggregated_zone[census_count_columns].isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bfwja4lyetf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of df_aggregated_zone with census data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>zone</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>total_population</th>\n",
       "      <th>total_households</th>\n",
       "      <th>commute_public_transit</th>\n",
       "      <th>commute_taxi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>14</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>500</td>\n",
       "      <td>30030.0</td>\n",
       "      <td>9909.0</td>\n",
       "      <td>4646.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>20292</td>\n",
       "      <td>19705.0</td>\n",
       "      <td>9341.0</td>\n",
       "      <td>4239.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Arrochar/Fort Wadsworth</td>\n",
       "      <td>165</td>\n",
       "      <td>14356.0</td>\n",
       "      <td>5143.0</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Astoria</td>\n",
       "      <td>7730</td>\n",
       "      <td>76914.0</td>\n",
       "      <td>35711.0</td>\n",
       "      <td>25373.0</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Astoria Park</td>\n",
       "      <td>64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Auburndale</td>\n",
       "      <td>224</td>\n",
       "      <td>20544.0</td>\n",
       "      <td>7363.0</td>\n",
       "      <td>2748.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Baisley Park</td>\n",
       "      <td>4433</td>\n",
       "      <td>39289.0</td>\n",
       "      <td>11970.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>Bath Beach</td>\n",
       "      <td>358</td>\n",
       "      <td>24895.0</td>\n",
       "      <td>8697.0</td>\n",
       "      <td>4565.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pulocationid                     zone  trip_count  total_population  \\\n",
       "0             1           Newark Airport         153               NaN   \n",
       "1             2              Jamaica Bay          14              45.0   \n",
       "2             3  Allerton/Pelham Gardens         500           30030.0   \n",
       "3             4            Alphabet City       20292           19705.0   \n",
       "4             6  Arrochar/Fort Wadsworth         165           14356.0   \n",
       "5             7                  Astoria        7730           76914.0   \n",
       "6             8             Astoria Park          64               1.0   \n",
       "7             9               Auburndale         224           20544.0   \n",
       "8            10             Baisley Park        4433           39289.0   \n",
       "9            11               Bath Beach         358           24895.0   \n",
       "\n",
       "   total_households  commute_public_transit  commute_taxi  \n",
       "0               NaN                     NaN           NaN  \n",
       "1              18.0                     3.0           0.0  \n",
       "2            9909.0                  4646.0          53.0  \n",
       "3            9341.0                  4239.0          71.0  \n",
       "4            5143.0                  2233.0           0.0  \n",
       "5           35711.0                 25373.0         329.0  \n",
       "6               0.0                     0.0           0.0  \n",
       "7            7363.0                  2748.0           7.0  \n",
       "8           11970.0                  6445.0         267.0  \n",
       "9            8697.0                  4565.0          80.0  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sample of df_aggregated_zone with census data:\")\n",
    "df_aggregated_zone[['pulocationid', 'zone', 'trip_count', 'total_population', \n",
    "                    'total_households', 'commute_public_transit', 'commute_taxi']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "derived_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived demographic and income metrics for aggregated datasets\n",
    "def add_derived_metrics(df):\n",
    "    df['trips_per_capita'] = df['trip_count'] / df['total_population']\n",
    "    df['poverty_rate'] = df['population_below_poverty'] / df['total_population']\n",
    "    df['pct_no_vehicle'] = df['households_no_vehicle'] / df['total_households']\n",
    "    df['pct_minority'] = (\n",
    "        df['race_black_alone'] + df['ethnicity_hispanic_latino']\n",
    "    ) / df['race_total']\n",
    "    df['pct_white'] = df['race_white_alone'] / df['race_total']\n",
    "    df['pct_public_transit'] = df['commute_public_transit'] / df['commuters_total']\n",
    "    df['pct_low_income'] = (\n",
    "        df['hh_income_under_10k'] + df['hh_income_10k_to_15k'] +\n",
    "        df['hh_income_15k_to_20k'] + df['hh_income_20k_to_25k']\n",
    "    ) / df['total_households']\n",
    "    df['pct_high_income'] = (\n",
    "        df['hh_income_150k_to_200k'] + df['hh_income_200k_plus']\n",
    "    ) / df['total_households']\n",
    "\n",
    "for df in (df_aggregated, df_aggregated_zone):\n",
    "    add_derived_metrics(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "wob3qn1x7ja",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved df_aggregated to ..\\input\\processed\\aggregated_data_time_zone.parquet\n",
      "Saved df_aggregated_zone to ..\\input\\processed\\aggregated_data_zone.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save aggregated dataframes to parquet\n",
    "PROCESSED_DIR = Path(\"../input/processed\")\n",
    "\n",
    "# Save df_aggregated (zone x hour x is_weekend level)\n",
    "df_aggregated.to_parquet(PROCESSED_DIR / \"aggregated_data_time_zone.parquet\", index=False)\n",
    "print(f\"Saved df_aggregated to {PROCESSED_DIR / 'aggregated_data_time_zone.parquet'}\")\n",
    "\n",
    "# Save df_aggregated_zone (zone level only)\n",
    "df_aggregated_zone.to_parquet(PROCESSED_DIR / \"aggregated_data_zone.parquet\", index=False)\n",
    "print(f\"Saved df_aggregated_zone to {PROCESSED_DIR / 'aggregated_data_zone.parquet'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s-p-global-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
